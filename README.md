# Predictive Modelling and Deployment  

This project demonstrates an end-to-end **machine learning workflow** for restaurant data, including:  

- **Data preprocessing**  
- **Feature engineering**  
- **Model training (regression + classification)**  
- **Experiment tracking and reproducibility with DVC**  
- **Data versioning with Git LFS**  

The workflow is fully reproducible using `dvc repro`, ensuring consistency across runs and portability across environments.  

---

## ğŸ“‚ Repository Structure  

.<br>
â”œâ”€â”€ .dvc/ # Local remote storage<br>
â”œâ”€â”€ data/ # Raw and intermediate datasets (Git LFS tracked)<br>
â”œâ”€â”€ models/ # Trained models (DVC tracked, not stored in Git)<br>
â”œâ”€â”€ notebooks/ # Exploratory analysis & PySpark experiments<br>
â”œâ”€â”€ scripts/ # Pipeline scripts<br>
â”œâ”€â”€ visualisations/ # Graphs and other visualisations<br>
â”œâ”€â”€ .dvcignore # Ignores temp/unwanted files in DVC<br>
â”œâ”€â”€ .gitattributes # Git LFS tracking<br>
â”œâ”€â”€ .gitignore # Ignores DVC outputs in Git<br>
â”œâ”€â”€ README.md # Project documentation<br>
â”œâ”€â”€ dvc.lock # Pipeline lock file (snapshots of dependencies/outputs)<br>
â”œâ”€â”€ dvc.yaml # DVC pipeline definition<br>
â”œâ”€â”€ models.dvc # Track models with DVC<br>
â””â”€â”€ requirements.txt # List of dependencies<br>

---

## âš™ï¸ Pipeline Overview  

The pipeline is defined in `dvc.yaml` and consists of three stages:  

1. **Preprocessing** (`preprocess`)  
   - Input: `data/zomato_df_final_data.csv`  
   - Script: `preprocess.py`  
   - Output: `data/preprocessed.csv`  

2. **Feature Engineering** (`feature_engineering`)  
   - Input: `data/preprocessed.csv`  
   - Script: `feature_engineer.py`  
   - Output: `data/engineered.csv`  

3. **Training** (`train_models`)  
   - Input: `data/engineered.csv`  
   - Script: `train.py`  
   - Outputs:  
     - `models/linear_regression.pkl`  
     - `models/svm_classifier.pkl`  
   - Also saves evaluation results in `results/`  

---

## ğŸš€ Usage  

### 1. Clone the Repository  
```bash
git clone https://github.com/nigelcheong/predictive-modelling-and-deployment-assignment
cd predictive-modelling-and-deployment-assignment
```
### 2. Install Dependencies
```bash
pip install -r requirements.txt
```
### 3. Pull Data and Models
```bash
git lfs pull
dvc pull
```
### 4. Reproduce the Pipeline
```bash
dvc repro
```
